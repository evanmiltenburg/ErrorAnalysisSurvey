{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8fe095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c700a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(records, question):\n",
    "    \"Get distribution of answers, for a given question.\"\n",
    "    c = Counter(record[question] for record in records)\n",
    "    total = sum(c.values())\n",
    "    empty = c['']\n",
    "    counts = {key: {\"number\": value, \n",
    "                    \"percentage\": (value/total) * 100, \n",
    "                    \"percentage_answered\": (value/(total-empty)) * 100} \n",
    "                for key, value in c.items()}\n",
    "    try:\n",
    "        del counts['']['percentage_answered']\n",
    "    except:\n",
    "        pass\n",
    "    return counts\n",
    "\n",
    "\n",
    "def get_questions(question, number):\n",
    "    \"Get questions for a range of questions in a grid.\"\n",
    "    texts = []\n",
    "    for i in range(1,number+1):\n",
    "        item = f'Q{question}_{i}'\n",
    "        text = questions[item]\n",
    "        text = text.split('-')[-1].strip()\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "\n",
    "def get_texts(records, question):\n",
    "    \"Get answer texts.\"\n",
    "    texts = []\n",
    "    for record in records:\n",
    "        answer = record[question]\n",
    "        identifier = record['ResponseId']\n",
    "        if not answer == '':\n",
    "            texts.append([identifier, answer])\n",
    "    return texts\n",
    "\n",
    "\n",
    "def basic_stats(records, question):\n",
    "    \"Print basic statistics about the results.\"\n",
    "    counts = distribution(records, question)\n",
    "    for key, results in counts.items():\n",
    "        if not key == '':\n",
    "            print(f\"{key}: {results['number']} ({results['percentage_answered']:.2f}%)\")\n",
    "\n",
    "    \n",
    "def underscored(base, number, records):\n",
    "    \"Get answer distribution for all subquestions.\"\n",
    "    results = dict()\n",
    "    for i in range(1, number+1):\n",
    "        question = f\"Q{base}_{i}\"\n",
    "        results[question] = distribution(records, question)\n",
    "    return results\n",
    "\n",
    "\n",
    "def agreement(counts):\n",
    "    \"Select percentage answered for all answers except the empty string.\"\n",
    "    results = dict()\n",
    "    for answer in ['Strongly disagree', 'Somewhat disagree', 'Neither agree nor disagree', 'Somewhat agree', 'Strongly agree']:\n",
    "        try:\n",
    "            results[answer] = counts[answer]['percentage_answered']\n",
    "        except:\n",
    "            results[answer] = 0\n",
    "    return results\n",
    "\n",
    "\n",
    "# No longer needed:\n",
    "# def enumerate_ids(iterable):\n",
    "#     \"Enumerate iterable with zero-padded IDs.\"\n",
    "#     for i, element in enumerate(iterable):\n",
    "#         yield 'comment-' + str(i).zfill(3), element\n",
    "\n",
    "\n",
    "def write_texts(texts, filename):\n",
    "    \"Write texts from a list to a file.\"\n",
    "    with open('./texts/' + filename,'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['identifier', 'comment', 'code'])\n",
    "        writer.writerows([row + ['Original comment'] for row in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4967c0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emiel/opt/anaconda3/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:221: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"[Distributed] Perceptions of Error Analysis_February 21, 2022_06.54.xlsx\")\n",
    "df = df.fillna('')\n",
    "records = df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf69cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "consented = [record for record in records if str(record['Q1 ']).startswith(\"Yes\")]\n",
    "\n",
    "print(len(consented))\n",
    "\n",
    "# For subgroup analysis:\n",
    "academia = [record for record in records if str(record['Q2'])=='Academia']\n",
    "industry = [record for record in records if str(record['Q2'])=='Industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a9a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, here are all questions:\n",
    "questions = records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d1ca66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'StartDate': 'Start Date',\n",
       " 'EndDate': 'End Date',\n",
       " 'Status': 'Response Type',\n",
       " 'Progress': 'Progress',\n",
       " 'Duration (in seconds)': 'Duration (in seconds)',\n",
       " 'Finished': 'Finished',\n",
       " 'RecordedDate': 'Recorded Date',\n",
       " 'ResponseId': 'Response ID',\n",
       " 'DistributionChannel': 'Distribution Channel',\n",
       " 'UserLanguage': 'User Language',\n",
       " 'Q1 ': 'Informed consent\\n\\n \\n\\nThis is the consent form for our study about the status of error analysis in NLG. Full details about this study were provided on the previous page. If you want to read this information again, you can go back to the previous page. If anything is still unclear about this study, please contact: C.W.J.vanMiltenburg@tilburguniversity.edu\\n\\n \\n\\nConsent\\n\\nBy consenting, you indicate that you have read the description on the previous page, that you are voluntarily taking part in this study, and that you allow for your data to be processed. This means that:\\n\\n\\n\\tYou agree to your responses being anonymously recorded.\\n\\tYour answers will be used to study the status of error analysis in NLG, and may be used in future publications pertaining to this topic.\\n\\tThe data will be shared with our research team, with both local (hard drive) and online (protected cloud drive) backups. This data will be stored indefinitely, and made public upon completion of our research. Note again that none of your answers can be traced back to you.\\n\\tYou acknowledge that there is no financial compensation for taking part in this study.\\n\\n\\n \\n\\nNote that you may still withdraw your consent after completing this form, without any negative consequences. We will delete all incomplete forms from our study.\\n\\n \\n\\nDo you consent?\\n\\nDo you agree to take part in this study? If you consent, please indicate this below by clicking “Yes”.  If you click “No”, you will be directed to the end of this questionnaire. You may also close this page to stop participating in this study.',\n",
       " 'Q2': 'Are you in academia or in industry? (If you have a dual affiliation, please respond with your dominant affiliation in mind.)',\n",
       " 'Q3': 'How many years have you been working in NLG?',\n",
       " 'Q4': 'Do you remember reading any NLG papers that include an error analysis?',\n",
       " 'Q5': 'Did you find the error analyses to be useful?',\n",
       " 'Q6': \"What did you find useful about the error analyses you've seen?\",\n",
       " 'Q7': \"Why didn't you find the error analyses to be useful?\",\n",
       " 'Q8': \"Is it surprising to you that you haven't seen any published error analyses? - Selected Choice\",\n",
       " 'Q8_1_TEXT': \"Is it surprising to you that you haven't seen any published error analyses? - Yes, because: - Text\",\n",
       " 'Q8_2_TEXT': \"Is it surprising to you that you haven't seen any published error analyses? - No, because: - Text\",\n",
       " 'Q9': 'Have you ever carried out an error analysis?',\n",
       " 'Q10': 'What did you find challenging or difficult about carrying out an error analysis?',\n",
       " 'Q11': 'Did you feel like there were enough resources/reference material for you to carry out an error analysis?',\n",
       " 'Q28': \"Do you think you'll carry out an error analysis again in the future?\",\n",
       " 'Q29': 'Could you explain your answer to the previous question?',\n",
       " 'Q12': 'Have you ever considered carrying out an error analysis?',\n",
       " 'Q13': \"What is the reason you haven't carried out an error analysis?\",\n",
       " 'Q14': 'Are you willing to carry out an error analysis?',\n",
       " 'Q15': 'For what kinds of papers do you think error analyses may be useful?',\n",
       " 'Q16_1': 'I would be more likely to carry out an analysis in a conference/journal paper if… - There was a higher page limit.',\n",
       " 'Q16_2': 'I would be more likely to carry out an analysis in a conference/journal paper if… - There would be an existing error taxonomy that I could use.',\n",
       " 'Q16_3': 'I would be more likely to carry out an analysis in a conference/journal paper if… - There would be dedicated annotation tools for error analysis that I could use.',\n",
       " 'Q16_4': 'I would be more likely to carry out an analysis in a conference/journal paper if… - There would be a crowdsourcing template for carrying out error analyses.',\n",
       " 'Q16_5': 'I would be more likely to carry out an analysis in a conference/journal paper if… - Reviewers paid more attention to error analyses.',\n",
       " 'Q16_6': 'I would be more likely to carry out an analysis in a conference/journal paper if… - There were an available pool of annotators or crowd workers',\n",
       " 'Q16_7': 'I would be more likely to carry out an analysis in a conference/journal paper if… - I had more time.',\n",
       " 'Q16_8': 'I would be more likely to carry out an analysis in a conference/journal paper if… - I had more money.',\n",
       " 'Q16_9': 'I would be more likely to carry out an analysis in a conference/journal paper if… - I had more collaborators.',\n",
       " 'Q17': 'Are there any other barriers that prevent you from carrying out an error analysis?',\n",
       " 'Q18_1': 'Please indicate whether you agree or disagree with the following statements - There should be more error analyses in the NLG literature',\n",
       " 'Q18_2': 'Please indicate whether you agree or disagree with the following statements - Error analyses are a valuable part of a paper.',\n",
       " 'Q18_3': 'Please indicate whether you agree or disagree with the following statements - Carrying out an error analysis is enjoyable.',\n",
       " 'Q18_4': 'Please indicate whether you agree or disagree with the following statements - Carrying out an error analysis is boring/tedious.',\n",
       " 'Q18_5': 'Please indicate whether you agree or disagree with the following statements - Error analyses are necessary to fully evaluate the performance of an NLG system.',\n",
       " 'Q18_6': 'Please indicate whether you agree or disagree with the following statements - Knowing what errors a system makes is helpful for future research.',\n",
       " 'Q18_7': 'Please indicate whether you agree or disagree with the following statements - Knowing what errors a system makes is helpful for practitioners/NLG in industry.',\n",
       " 'Q18_8': 'Please indicate whether you agree or disagree with the following statements - If you publish at a conference, and you present an NLG system as one of your main contributions, you should include an error analysis.',\n",
       " 'Q18_9': 'Please indicate whether you agree or disagree with the following statements - If you publish in a journal, and you present an NLG system as one of your main contributions, you should include an error analysis.',\n",
       " 'Q19': 'I am … likely to include an error analysis in a journal article than/as I would be for a conference publication.',\n",
       " 'Q27': 'Please explain your answer to the previous question:',\n",
       " 'Q20': 'Are there currently enough resources to support error analysis? - Selected Choice',\n",
       " 'Q20_2_TEXT': 'Are there currently enough resources to support error analysis? - No, I am still missing: - Text',\n",
       " 'Q21': 'Besides resources, are there any other factors that would make it more likely for you to carry out an error analysis?',\n",
       " 'Q23': 'What else would you recommend that authors should include in an error analysis?',\n",
       " 'Q24': 'This is the final question. Is there anything you would like to add or comment on?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3539ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO:\\n- Subgroup analysis: academia vs industry\\n- Heatmap tables\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "- Subgroup analysis: academia vs industry\n",
    "- Heatmap tables\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52cf87",
   "metadata": {},
   "source": [
    "# Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f465fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academia: 45 (83.33%)\n",
      "Industry: 8 (14.81%)\n",
      "Other: 1 (1.85%)\n"
     ]
    }
   ],
   "source": [
    "# Where do people come from?\n",
    "basic_stats(consented, \"Q2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec484112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6-10 years: 5 (9.43%)\n",
      "Less than 2 years: 11 (20.75%)\n",
      "2-5 years: 22 (41.51%)\n",
      "11 or more years: 10 (18.87%)\n",
      "I don't work in NLG: 5 (9.43%)\n"
     ]
    }
   ],
   "source": [
    "# Time spent working in NLG:\n",
    "basic_stats(consented, \"Q3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2717d63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes: 29 (64.44%)\n",
      "No: 16 (35.56%)\n"
     ]
    }
   ],
   "source": [
    "# Read an error analysis:\n",
    "basic_stats(consented, \"Q4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8f0e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, because:: 3 (42.86%)\n",
      "No, because:: 4 (57.14%)\n"
     ]
    }
   ],
   "source": [
    "# Is it surprising that you haven't read an error analysis?\n",
    "basic_stats(consented, \"Q8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6939c21b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"list\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2da77f9dda06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Why is it surprising?:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsented\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Q8_1_TEXT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwrite_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"surprising_because.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b94b7913fa1b>\u001b[0m in \u001b[0;36mwrite_texts\u001b[0;34m(texts, filename)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'identifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'comment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Original comment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-b94b7913fa1b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'identifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'comment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Original comment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"list\") to tuple"
     ]
    }
   ],
   "source": [
    "# Why is it surprising?:\n",
    "texts = get_texts(consented, 'Q8_1_TEXT')\n",
    "write_texts(texts, \"surprising_because.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is it not surprising?:\n",
    "texts = get_texts(consented, 'Q8_2_TEXT')\n",
    "write_texts(texts, \"not_surprising_because.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcab7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carried out an error analysis:\n",
    "basic_stats(consented, 'Q9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Willing to carry one out again (only people who answered 'yes'):\n",
    "basic_stats(consented, 'Q28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation for previous question\n",
    "texts = get_texts(consented, 'Q29')\n",
    "write_texts(texts, \"carry_out_again_because.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce605668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considered carrying one out (only people who answered 'no'):\n",
    "basic_stats(consented, 'Q12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Willing to carry one out (only people who answered 'no'):\n",
    "basic_stats(consented, 'Q14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4483a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasons for not doing it:\n",
    "texts = get_texts(consented, 'Q13')\n",
    "write_texts(texts, \"reason_for_not_carrying_out.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d153991",
   "metadata": {},
   "source": [
    "# Usefulness of error analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found useful:\n",
    "basic_stats(consented, 'Q5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was useful about the analyses?:\n",
    "texts = get_texts(consented, 'Q6')\n",
    "write_texts(texts, \"uses_of_error_analysis.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For what kinds of papers are error analyses useful?:\n",
    "texts = get_texts(consented, 'Q15')\n",
    "write_texts(texts, \"kinds_of_papers.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasons for disappointment:\n",
    "texts = get_texts(consented, 'Q7')\n",
    "write_texts(texts, \"reasons_for_disappointment.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87d387",
   "metadata": {},
   "source": [
    "# Barriers and enabling factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenges:\n",
    "texts = get_texts(consented, 'Q10')\n",
    "write_texts(texts, \"challenges.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enough resources/reference materials at the time?\n",
    "basic_stats(consented,'Q11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9471c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = ['Strongly disagree', 'Somewhat disagree', 'Neither agree nor disagree', 'Somewhat agree', 'Strongly agree']\n",
    "records = []\n",
    "for question, counts in underscored(16,9,consented).items():\n",
    "    for answer in answers:\n",
    "        percentage = 0\n",
    "        if answer in counts:\n",
    "            percentage = counts[answer]['number'] # NOTE: Changed into number rather than percentage!\n",
    "        record = dict(question=question, answer=answer, percentage=percentage)\n",
    "        records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "# Pivot to make a square table:\n",
    "df = df.pivot(index='question', columns='answer', values='percentage')\n",
    "# Reorder columns:\n",
    "df = df[['Strongly disagree', 'Somewhat disagree', 'Neither agree nor disagree', 'Somewhat agree', 'Strongly agree']]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
    "ax = sns.heatmap(df,cmap=sns.light_palette(\"seagreen\", as_cmap=True),linewidth=1,cbar=False,annot=True)\n",
    "ax.xaxis.tick_top()\n",
    "plt.xticks(np.arange(5) + 0.5, labels=answers)\n",
    "plt.yticks(np.arange(9) + 0.5, labels=get_questions(16,9))\n",
    "plt.tick_params(top=False,left=False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title(\"I would be more likely to carry out an analysis in a conference/journal paper if…\", y=1.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Q16.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other barriers?\n",
    "texts = get_texts(consented, 'Q17')\n",
    "write_texts(texts, \"other_barriers.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67dca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enough resources/reference materials currently?\n",
    "basic_stats(consented,'Q20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974643a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is still missing?\n",
    "texts = get_texts(consented, 'Q20_2_TEXT')\n",
    "write_texts(texts, \"missing.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other factors that make it more likely for you to carry out an error analysis?\n",
    "texts = get_texts(consented, 'Q21')\n",
    "write_texts(texts, \"enabling.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491005ee",
   "metadata": {},
   "source": [
    "# General opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = ['Strongly disagree', 'Somewhat disagree', 'Neither agree nor disagree', 'Somewhat agree', 'Strongly agree']\n",
    "records = []\n",
    "for question, counts in underscored(18,9,consented).items():\n",
    "    for answer in answers:\n",
    "        percentage = 0\n",
    "        if answer in counts:\n",
    "            percentage = counts[answer]['number']\n",
    "        record = dict(question=question, answer=answer, percentage=percentage)\n",
    "        records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "# Pivot to make a square table:\n",
    "df = df.pivot(index='question', columns='answer', values='percentage')\n",
    "# Reorder columns:\n",
    "df = df[['Strongly disagree', 'Somewhat disagree', 'Neither agree nor disagree', 'Somewhat agree', 'Strongly agree']]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,4)\n",
    "ax = sns.heatmap(df,cmap=sns.light_palette(\"seagreen\", as_cmap=True),linewidth=1,cbar=False,annot=True)\n",
    "ax.xaxis.tick_top()\n",
    "plt.xticks(np.arange(5) + 0.5, labels=answers)\n",
    "plt.yticks(np.arange(9) + 0.5, labels=get_questions(18,9))\n",
    "plt.tick_params(top=False,left=False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title(\"...\", y=1.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Q18.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More/less/equally likely to include error analysis in journal\n",
    "basic_stats(consented, 'Q19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation for previous question:\n",
    "texts = get_texts(consented, 'Q27')\n",
    "write_texts(texts, \"explanation_journal_preference.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97adc381",
   "metadata": {},
   "source": [
    "# Requirements for reports of error analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7698cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = get_texts(consented, 'Q23')\n",
    "write_texts(texts, \"reporting_requirements.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d43a48",
   "metadata": {},
   "source": [
    "# General comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = get_texts(consented, 'Q24')\n",
    "write_texts(texts, \"general_comments.csv\")\n",
    "\n",
    "for ident, text in texts:\n",
    "    print(ident, text)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb620b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
